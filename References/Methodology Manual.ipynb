{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce4e8687-d0b8-46b9-8f2c-7cb631c2fe35",
   "metadata": {},
   "source": [
    "# üìò Methodology Manual\n",
    "\n",
    "## **1Ô∏è‚É£ Tools and Libraries Used**\n",
    "### **üõ† Tools:**\n",
    "- **Jupyter Notebook**: Used as the primary environment for writing and executing Python code.\n",
    "\n",
    "### **üìö Libraries Used:**\n",
    "- **Pandas**: For data manipulation and preprocessing.\n",
    "- **NumPy**: For numerical computations.\n",
    "- **Matplotlib**: For data visualization.\n",
    "- **Seaborn**: For advanced statistical plots.\n",
    "- **Pylab**: For integrating plotting with Python.\n",
    "- **SciPy**: For scientific computations and statistical analysis.\n",
    "- **Scikit-learn (Sklearn)**: For machine learning model implementation.\n",
    "\n",
    "---\n",
    "\n",
    "## **2Ô∏è‚É£ Defining Dependent and Independent Features**\n",
    "- **Dependent Feature (Target Variable)**:  \n",
    "  - The feature we are trying to predict.  \n",
    "  - Example: **Attrition** (1 = Employee left, 0 = Employee stayed).  \n",
    "\n",
    "- **Independent Features (Predictors)**:  \n",
    "  - Features that influence the target variable.  \n",
    "  - Example: `Age`, `ExperienceYearsAtThisCompany`, `OverTime`, `EmpJobSatisfaction`, etc.  \n",
    "\n",
    "---\n",
    "\n",
    "## **3Ô∏è‚É£ Balancing the Data**\n",
    "### **‚ö†Ô∏è Problem: Data Imbalance**\n",
    "- The dataset is **imbalanced**, meaning there are significantly more instances of one class than the other.  \n",
    "- An **imbalanced dataset** can cause the model to be biased towards the majority class, leading to poor predictions.  \n",
    "\n",
    "### **‚úÖ Solution: SMOTE (Synthetic Minority Oversampling Technique)**\n",
    "- **SMOTE** is a widely used **oversampling** technique that generates synthetic examples for the **minority class** rather than simply duplicating existing data.  \n",
    "- It creates **new data points** by interpolating between existing instances of the minority class.\n",
    "\n",
    "### **üõ† How SMOTE Works:**\n",
    "1. Randomly selects a **minority class** sample.\n",
    "2. Finds its **k-nearest neighbors**.\n",
    "3. Creates a **new synthetic data point** between the sample and one of its neighbors.\n",
    "4. Repeats the process until the dataset is balanced.\n",
    "\n",
    "---\n",
    "\n",
    "## **4Ô∏è‚É£ Splitting Training and Testing Data**\n",
    "- **80% of the data** is used for **training**.  \n",
    "- **20% of the data** is used for **testing**.  \n",
    "- The **train-test split** ensures that the model is evaluated on unseen data to test its generalizability.  \n",
    "\n",
    "---\n",
    "\n",
    "## **5Ô∏è‚É£ Algorithm Selection**\n",
    "### **üéØ AIM: Create a Model with Low Bias & Low Variance**\n",
    "To achieve an optimal balance between **bias and variance**, we experiment with **three algorithms**:\n",
    "\n",
    "---\n",
    "\n",
    "## **üîπ Support Vector Machine (SVM)**\n",
    "### **üìå What is SVM?**\n",
    "- SVM is a **supervised learning algorithm** used for **classification and regression tasks**.  \n",
    "- It finds the **optimal hyperplane** that best separates the data into different classes.  \n",
    "\n",
    "### **‚úÖ Advantages of SVM:**\n",
    "- Works well in **high-dimensional spaces**.\n",
    "- Effective when the number of dimensions is **greater than the number of samples**.\n",
    "- Robust against overfitting when using the right kernel.\n",
    "\n",
    "### **üìä Performance on Our Data:**\n",
    "- **Training Accuracy:** 96.61%  \n",
    "- **Test Accuracy:** 94.66% (slightly lower, indicating potential overfitting).  \n",
    "- After **Hyperparameter Tuning**, test accuracy increased to **98.28%**, but the model still overfits.  \n",
    "\n",
    "---\n",
    "\n",
    "## **üîπ Random Forest**\n",
    "### **üìå What is Random Forest?**\n",
    "- Random Forest is an **ensemble learning method** that combines multiple decision trees to improve accuracy.  \n",
    "- Uses **bagging (Bootstrap Aggregation)** to reduce variance.  \n",
    "\n",
    "### **‚úÖ Advantages of Random Forest:**\n",
    "- Handles **non-linear relationships** well.\n",
    "- Works well with both **categorical and numerical** data.\n",
    "- Reduces the risk of overfitting compared to a single decision tree.\n",
    "\n",
    "### **üìä Performance on Our Data:**\n",
    "- **Training Accuracy:** 100%  \n",
    "- **Test Accuracy:** 95.61%  \n",
    "- After **Hyperparameter Tuning**, the test accuracy **decreased**, suggesting **overfitting before tuning and underfitting after tuning**.  \n",
    "\n",
    "---\n",
    "\n",
    "## **üîπ Artificial Neural Network (Multilayer Perceptron - MLP Classifier)**\n",
    "### **üìå What is an ANN (MLP Classifier)?**\n",
    "- An **Artificial Neural Network (ANN)** is a computing system inspired by the human brain.\n",
    "- **Multilayer Perceptron (MLP)** is a type of ANN that consists of **multiple layers** of neurons.  \n",
    "- It learns by **adjusting weights** through **backpropagation**.  \n",
    "\n",
    "### **‚úÖ Advantages of ANN:**\n",
    "- Can capture **complex patterns** in the data.  \n",
    "- Works well with **both structured and unstructured data**.  \n",
    "- Can generalize well when trained properly.  \n",
    "\n",
    "### **üìä Performance on Our Data:**\n",
    "- **Training Accuracy:** 98.95%  \n",
    "- **Testing Accuracy:** 95.80%  \n",
    "- This model showed the best balance between **training and testing accuracy**, making it the most **generalizable model**.  \n",
    "\n",
    "---\n",
    "\n",
    "## **6Ô∏è‚É£ Final Model Selection**\n",
    "- **Artificial Neural Network (MLP Classifier)** is selected as the final model.  \n",
    "- It provides **high accuracy on both training and testing data** without excessive overfitting.  \n",
    "- This model will be used for **predicting employee attrition and performance analysis**.\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
